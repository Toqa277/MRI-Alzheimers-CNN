# Project Architecture:

- Data Acquisition: The dataset was retrieved from The Alzheimer’s Disease Neuroimaging Initiative (ADNI) composed of 941 3D images, categorized as follows: 399 images from cognitively normal (CN) participants, 282 from those with mild cognitive impairment (MCI), and 260 from Alzheimer’s disease (AD) patients.

- Data Preprocessing: Data Conversion to Standardized Format by Converting DICOM to NIfTI simplifies the file structure by combining multiple image slices into a single file. Bias Field Correction to enhancing image quality. Registration to ensure that common features overlap using the MNI152 template which serves as a standardized reference for brain imaging. Skull Stripping by removing non-brain tissues from MRI images that isolates the brain region. Normalization (Optional here) to produce consistent and comparable intensity values across different images. Slice Extraction (Only for 2D Model and Transfer Learning) by converting 3D MRI volumes into 2D slices to enhance computational efficiency and increase the number of training samples. Resizing images to a fixed resolution ensures consistent input sizes for CNNs facilitating compatibility with pre-trained models and improving training efficiency. Then finally Normalization (Mandatory) Min-max normalization was applied to scale the pixel intensity values to a range of 0 to 1, enhancing the models' performance.

- Train - Validation - Test Split:  The data was slitted into 80% for training (and 20% from this 80% was taken for validation): 20% for testing.

- Training using our three different models: 3D ResNet-18 CNN, 2D-Dual proposed CNN and VGG16 Transfer Learning Model on the training and validation sets over 50 epochs.

- Testing the three models by utilizing the three models to a multi-stage classification (AD, CN, MCI).

- Using Confusion Matrix, ROC curve, accuracy, precision, F1 score and Recall to evaluate our Findings.

# Design Decisions

- For preprocessing, MNI152 template was used for registration, A three slice from three different planes were extracted from each 3D T1w MRI images, Min-Max normalization (0,1) was done.

- Data Splitting was as mentioned before 80% to 20% training: testing respectively.

-   3D ResNet-18 CNN Hyperparameters:
Learning rate : 1e-4
Number of epochs : 50
Loss function / activation function : cross entropy , ReLu
Optimizer : Adam 
Batch size :  16
Dropout rate : 30%
Classifier : softmax 

- 2D-Dual proposed CNN Hyperparameters:

Learning rate : 1e-3 . Reduced by 15% every epoch using a learning rate scheduler.
Number of epochs : 50
Loss function / activation function : cross entropy , ReLu
Optimizer : Adam 
Batch size :  8
Dropout rate : 30% and 50%
L2 Regularization: Applied to all Conv2D layers  and dense layers . with penalty strength: l2(0.01) 
Classifier : softmax 

- VGG16 Transfer Learning Model Hyperparameters:

Learning rate : 1e-5 
Number of epochs : 30
Loss function / activation function : cross entropy , ReLu
Optimizer : Adam 
Batch size :  16
Dropout rate : 50%
L2 Regularization: Applied to all Conv2D layers  and dense layers . with penalty strength: l2(0.001) 
Classifier : softmax 


# Algorithms use and 


- 3D ResNet-18
ResNet-18 is a deep learning network built on the Residual Learning framework, where identity shortcut connections bypass layers, allowing input to connect directly to the output. Each residual block learns a mapping F(x) + x,  optimizing residual functions instead of full transformations, which prevents the vanishing gradient problem. 

- 2D-Dual proposed CNN
It is a dual-CNN architecture that consists of CNN1 and CNN2 which utilizes complementary feature extraction by using different filter sizes to capture both local and global patterns. This duality enhances representation learning, improving robustness and accuracy compared to single-model approaches. 

- VGG16 Transfer Learning
VGG-16 has already been trained on the ImageNet dataset, which comprises more than 14 million images of different categories. As the authors Simonyan and Zisserman depicted, VGG16 is relatively simple, comprising 16 weighed layers. Moreover, it uses small, consistent, unlike other networks, 3x3 convolutional filters and 2x2 max-pooling layers. The architecture design enables the extraction of more complex features and yields enhanced performance in large-scale image recognition tasks such as our task in MRI of AD patients.


# Dependencies

Python: 3.8
TensorFlow: 2.12.0
Keras: 2.12.0 
PyTorch: 2.0.1
torchvision: 0.15.2
nibabel: 5.1.0 
dicom2nifti: 2.4.7 
NumPy: 1.23.5
Matplotlib: 3.7.2 
Seaborn: 0.12.2 
scikit-learn: 1.3.1
dicom2nifti: 2.4.7
ANTsPy: 0.3.3
