{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8d9c85b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:03.601076Z",
     "iopub.status.busy": "2025-01-05T17:01:03.600719Z",
     "iopub.status.idle": "2025-01-05T17:01:12.632251Z",
     "shell.execute_reply": "2025-01-05T17:01:12.631591Z"
    },
    "papermill": {
     "duration": 9.03836,
     "end_time": "2025-01-05T17:01:12.633865",
     "exception": false,
     "start_time": "2025-01-05T17:01:03.595505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input,decode_predictions\n",
    "import tensorflow as tf  # maybe\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import shutil\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Concatenate, Conv2D, GlobalMaxPooling2D, Dense, BatchNormalization, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Device configuration\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570896cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:12.642397Z",
     "iopub.status.busy": "2025-01-05T17:01:12.641913Z",
     "iopub.status.idle": "2025-01-05T17:01:13.207923Z",
     "shell.execute_reply": "2025-01-05T17:01:13.207011Z"
    },
    "papermill": {
     "duration": 0.571234,
     "end_time": "2025-01-05T17:01:13.209129",
     "exception": false,
     "start_time": "2025-01-05T17:01:12.637895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "GPU available (YESS!!!!)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if \"GPU\" not in device_name:\n",
    "    print(\"GPU device not found\")\n",
    "    \n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not available :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "005bc8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:13.217345Z",
     "iopub.status.busy": "2025-01-05T17:01:13.217069Z",
     "iopub.status.idle": "2025-01-05T17:01:13.220192Z",
     "shell.execute_reply": "2025-01-05T17:01:13.219557Z"
    },
    "papermill": {
     "duration": 0.008479,
     "end_time": "2025-01-05T17:01:13.221479",
     "exception": false,
     "start_time": "2025-01-05T17:01:13.213000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = \"/kaggle/input/split-data-vol2/Split_Data_vol2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc3e666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:13.228855Z",
     "iopub.status.busy": "2025-01-05T17:01:13.228645Z",
     "iopub.status.idle": "2025-01-05T17:01:13.241214Z",
     "shell.execute_reply": "2025-01-05T17:01:13.240568Z"
    },
    "papermill": {
     "duration": 0.017456,
     "end_time": "2025-01-05T17:01:13.242358",
     "exception": false,
     "start_time": "2025-01-05T17:01:13.224902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['val', 'test', 'train']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(dataset)\n",
    "os.path.os.listdir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66a14541",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:13.249787Z",
     "iopub.status.busy": "2025-01-05T17:01:13.249583Z",
     "iopub.status.idle": "2025-01-05T17:01:13.253001Z",
     "shell.execute_reply": "2025-01-05T17:01:13.252220Z"
    },
    "papermill": {
     "duration": 0.008352,
     "end_time": "2025-01-05T17:01:13.254154",
     "exception": false,
     "start_time": "2025-01-05T17:01:13.245802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset,\"train\")\n",
    "test_dir = os.path.join(dataset,\"test\")\n",
    "val_dir = os.path.join(dataset,\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5c8e0ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:13.261938Z",
     "iopub.status.busy": "2025-01-05T17:01:13.261741Z",
     "iopub.status.idle": "2025-01-05T17:01:13.269574Z",
     "shell.execute_reply": "2025-01-05T17:01:13.268914Z"
    },
    "papermill": {
     "duration": 0.012999,
     "end_time": "2025-01-05T17:01:13.270696",
     "exception": false,
     "start_time": "2025-01-05T17:01:13.257697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MCI', 'AD', 'CN']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.os.listdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf48c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:13.278165Z",
     "iopub.status.busy": "2025-01-05T17:01:13.277973Z",
     "iopub.status.idle": "2025-01-05T17:01:15.999925Z",
     "shell.execute_reply": "2025-01-05T17:01:15.999253Z"
    },
    "papermill": {
     "duration": 2.727091,
     "end_time": "2025-01-05T17:01:16.001237",
     "exception": false,
     "start_time": "2025-01-05T17:01:13.274146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1794 files belonging to 3 classes.\n",
      "Found 451 files belonging to 3 classes.\n",
      "Found 563 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Manually define label mapping  \n",
    "label_mapping = {  \n",
    "    'AD': 0,  # Alzheimer's Disease  \n",
    "    'CN': 1,  # Cognitively Normal  \n",
    "    'MCI': 2   # Mild Cognitive Impairment  \n",
    "}  \n",
    "\n",
    "# Normalization layer  \n",
    "normalization_layer = layers.Rescaling(1./255)  \n",
    "\n",
    "# Preprocess function  \n",
    "def preprocess_data(images, labels):  \n",
    "    images = normalization_layer(images)  # Normalize images to [0, 1]  \n",
    "    return images, labels  \n",
    "\n",
    "# Load datasets with processing  \n",
    "def load_dataset(directory):  \n",
    "    return tf.keras.utils.image_dataset_from_directory(  \n",
    "        directory,  \n",
    "        image_size=(224, 224),  \n",
    "        color_mode=\"grayscale\",  \n",
    "        batch_size=16,  \n",
    "        label_mode='categorical'  # this will map labels based on folder names  \n",
    "    ).map(lambda x, y: preprocess_data(x, y))  \n",
    "\n",
    "# Load datasets  \n",
    "train_ds = load_dataset(train_dir)\n",
    "val_ds = load_dataset(val_dir)\n",
    "test_ds = load_dataset(test_dir)\n",
    "\n",
    "# To extract manual labels, create a custom labelling function  \n",
    "def manual_label_extractor(labels):  \n",
    "    return tf.one_hot(tf.argmax(labels, axis=-1), depth=len(label_mapping))  \n",
    "\n",
    "# Set the labels manually  \n",
    "train_ds = train_ds.map(lambda x, y: (x, y))\n",
    "val_ds = val_ds.map(lambda x, y: (x, y))\n",
    "test_ds = test_ds.map(lambda x, y: (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b137b2",
   "metadata": {
    "papermill": {
     "duration": 0.003784,
     "end_time": "2025-01-05T17:01:16.009386",
     "exception": false,
     "start_time": "2025-01-05T17:01:16.005602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b94291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:16.017859Z",
     "iopub.status.busy": "2025-01-05T17:01:16.017635Z",
     "iopub.status.idle": "2025-01-05T17:01:20.741822Z",
     "shell.execute_reply": "2025-01-05T17:01:20.740881Z"
    },
    "papermill": {
     "duration": 4.730118,
     "end_time": "2025-01-05T17:01:20.743303",
     "exception": false,
     "start_time": "2025-01-05T17:01:16.013185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: [489, 765, 540]\n",
      "Val class distribution: [123, 192, 136]\n",
      "Test class distribution: [153, 240, 170]\n"
     ]
    }
   ],
   "source": [
    "# Function to count class distribution\n",
    "def count_classes(dataset):\n",
    "    class_counts = [0] * len(label_mapping)  # Initialize a list to hold class counts\n",
    "\n",
    "    # Iterate over the dataset and count instances of each class\n",
    "    for _, labels in dataset:\n",
    "        class_indices = tf.argmax(labels, axis=-1)  # Get the index of the class for each sample\n",
    "        for idx in class_indices.numpy():\n",
    "            class_counts[idx] += 1\n",
    "    \n",
    "    return class_counts  # Return the correct variable\n",
    "\n",
    "# Example usage to count classes in the training set\n",
    "print(\"Train class distribution:\", count_classes(train_ds))\n",
    "print(\"Val class distribution:\", count_classes(val_ds))\n",
    "print(\"Test class distribution:\", count_classes(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b19349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:20.752384Z",
     "iopub.status.busy": "2025-01-05T17:01:20.752083Z",
     "iopub.status.idle": "2025-01-05T17:01:20.819571Z",
     "shell.execute_reply": "2025-01-05T17:01:20.818603Z"
    },
    "papermill": {
     "duration": 0.073627,
     "end_time": "2025-01-05T17:01:20.821242",
     "exception": false,
     "start_time": "2025-01-05T17:01:20.747615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: (16, 224, 224, 1)\n",
      "Label batch shape: (16, 3)\n",
      "Labels (one-hot encoded): [[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "Image batch shape: (16, 224, 224, 1)\n",
      "Label batch shape: (16, 3)\n",
      "Labels (one-hot encoded): [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Inspect some samples from the dataset\n",
    "for images, labels in val_ds.take(2):  # Take one batch\n",
    "    print(f\"Image batch shape: {images.shape}\")\n",
    "    print(f\"Label batch shape: {labels.shape}\")\n",
    "    print(f\"Labels (one-hot encoded): {labels.numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff3d64f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:20.830730Z",
     "iopub.status.busy": "2025-01-05T17:01:20.830486Z",
     "iopub.status.idle": "2025-01-05T17:01:20.833657Z",
     "shell.execute_reply": "2025-01-05T17:01:20.833037Z"
    },
    "papermill": {
     "duration": 0.008959,
     "end_time": "2025-01-05T17:01:20.834934",
     "exception": false,
     "start_time": "2025-01-05T17:01:20.825975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freeze_layers(model, layer_indices):\n",
    "    for i in layer_indices:\n",
    "        model.layers[i].trainable = False\n",
    "# freeze_layers(base_model, layer_indices=list(range(0, 15)))\n",
    "# print(\"The following layers will be frozen:\")\n",
    "# for i, layer in enumerate(base_model.layers[:15]):\n",
    "#     print(f\"Layer {i} - {layer.name} - Trainable: {layer.trainable}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd7ff9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:20.843651Z",
     "iopub.status.busy": "2025-01-05T17:01:20.843436Z",
     "iopub.status.idle": "2025-01-05T17:01:20.848515Z",
     "shell.execute_reply": "2025-01-05T17:01:20.847723Z"
    },
    "papermill": {
     "duration": 0.010786,
     "end_time": "2025-01-05T17:01:20.849742",
     "exception": false,
     "start_time": "2025-01-05T17:01:20.838956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_path = \"/kaggle/input/vgg16/tensorflow2/default/1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "os.path.exists(weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8935d077",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T17:01:20.858576Z",
     "iopub.status.busy": "2025-01-05T17:01:20.858319Z",
     "iopub.status.idle": "2025-01-05T17:01:21.824568Z",
     "shell.execute_reply": "2025-01-05T17:01:21.823186Z"
    },
    "papermill": {
     "duration": 0.972056,
     "end_time": "2025-01-05T17:01:21.825801",
     "exception": true,
     "start_time": "2025-01-05T17:01:20.853745",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Undefined shapes are not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-a9beb431b812>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Model summary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Undefined shapes are not supported."
     ]
    }
   ],
   "source": [
    "# Load the pre-trained VGG16 model\n",
    "base_model = VGG16(\n",
    "    include_top=False,  # Exclude the classification layer\n",
    "    weights=weights_path,  # Pre-trained weights on ImageNet\n",
    "    input_shape=(224, 224, 3),  # Input shape for VGG16\n",
    "    pooling=\"max\"  # Use default feature maps output\n",
    ")\n",
    "## Define the input layer for grayscale images\n",
    "inputs = Input(shape=(224, 224, 1))  # Grayscale input (1 channel)\n",
    "\n",
    "# Convert grayscale to RGB by replicating the single channel\n",
    "rgb_inputs = Concatenate()([inputs, inputs, inputs])\n",
    "\n",
    "# Preprocess the inputs for VGG16\n",
    "processed_inputs = preprocess_input(rgb_inputs)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the final model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalMaxPooling2D(),\n",
    "    layers.Dense(128, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, kernel_regularizer=regularizers.l2(0.001), activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(3, activation='softmax', name='predictions')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(1e-4),  # Slightly higher learning rate\n",
    "    loss=CategoricalCrossentropy(),  # No need for 'from_logits=True' here\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52be85ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T16:30:32.567097Z",
     "iopub.status.busy": "2025-01-05T16:30:32.566802Z",
     "iopub.status.idle": "2025-01-05T16:34:12.112582Z",
     "shell.execute_reply": "2025-01-05T16:34:12.111259Z",
     "shell.execute_reply.started": "2025-01-05T16:30:32.567076Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "track_history = model.fit(train_ds, validation_data=val_ds,\n",
    "                          callbacks=[tf.keras.callbacks.EarlyStopping(patience=30, restore_best_weights=True)], epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b36140",
   "metadata": {
    "execution": {
     "execution_failed": "2025-01-03T04:07:13.814Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the last checkpoint\n",
    "model = load_model(checkpoint_path)\n",
    "\n",
    "# Continue training\n",
    "track_history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    initial_epoch=11,  # Start from the last completed epoch\n",
    "    epochs=30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927d78b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T16:28:35.886636Z",
     "iopub.status.busy": "2025-01-05T16:28:35.886323Z",
     "iopub.status.idle": "2025-01-05T16:28:36.307843Z",
     "shell.execute_reply": "2025-01-05T16:28:36.306858Z",
     "shell.execute_reply.started": "2025-01-05T16:28:35.886616Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'{\"VGG16\"} - Training and Validation Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'{\"VGG16\"} - Training and Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_history(track_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e7124",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T15:03:45.730855Z",
     "iopub.status.busy": "2025-01-05T15:03:45.730545Z",
     "iopub.status.idle": "2025-01-05T15:03:45.739560Z",
     "shell.execute_reply": "2025-01-05T15:03:45.738566Z",
     "shell.execute_reply.started": "2025-01-05T15:03:45.730830Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to evaluate one model and return metrics\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import label_binarize\n",
    "def evaluate_model(model, test_ds, num_classes):\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(test_ds)\n",
    "    print(f\"Test Loss: {test_loss}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "    # Extract test images and labels\n",
    "    test_images = np.concatenate([x.numpy() for x, _ in test_ds])\n",
    "    test_labels = np.concatenate([y.numpy() for _, y in test_ds])\n",
    "\n",
    "    test_images = np.array(test_images)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    # Predict class probabilities\n",
    "    predictions = model.predict(test_images)  # Use only one set of test images\n",
    "    predicted_classes = np.argmax(predictions, axis=1)       # Get the predicted class indices\n",
    "    true_classes = np.argmax(test_labels, axis=1)            # Convert one-hot labels to class indices\n",
    "\n",
    "    return test_loss, test_accuracy, true_classes, predicted_classes, predictions\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(true_classes, predicted_classes, class_names):\n",
    "    cm = confusion_matrix(true_classes, predicted_classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap='viridis', values_format='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(predictions, true_classes, num_classes):\n",
    "    # Binarize the test labels (for multi-class ROC)\n",
    "    y_test_bin = label_binarize(true_classes, classes=np.arange(num_classes))\n",
    "\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], predictions[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(num_classes):\n",
    "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line for random guessing\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5928f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-05T16:28:44.087468Z",
     "iopub.status.busy": "2025-01-05T16:28:44.087112Z",
     "iopub.status.idle": "2025-01-05T16:28:48.979476Z",
     "shell.execute_reply": "2025-01-05T16:28:48.978621Z",
     "shell.execute_reply.started": "2025-01-05T16:28:44.087436Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define number of classes and class names (like ['AD', 'CN', 'MCI'])\n",
    "num_classes = 3\n",
    "class_names = ['AD', 'CN', 'MCI']\n",
    "\n",
    "# Evaluate and plot for each model\n",
    "\n",
    "test_loss, test_accuracy, true_classes, predicted_classes, predictions = evaluate_model(model, test_ds, num_classes)\n",
    "plot_confusion_matrix(true_classes, predicted_classes, class_names)\n",
    "plot_roc_curve(predictions, true_classes, num_classes)\n",
    "\n",
    "    # Generate and print classification report\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_names)\n",
    "print(f\"Classification Report for {'VGG16'}:\\n{report}\")\n",
    "\n",
    "\n",
    "# track_history.history['test_accuracy_cnn1'] = test_accuracy\n",
    "\n",
    "\n",
    "# # Plotting Training, Validation, and Test accuracies\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.plot(track_history.history['accuracy'], label='Training Accuracy VGG16')\n",
    "# plt.plot(track_history.history['val_accuracy'], label='Validation Accuracy VGG16')\n",
    "# plt.axhline(y=track_history.history['test_accuracy_VGG16'], color='b', linestyle='--', label='Test Accuracy VGG16')\n",
    "\n",
    "\n",
    "\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.title('Training, Validation, and Test Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6415096,
     "sourceId": 10358563,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6415242,
     "sourceId": 10358770,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 209576,
     "modelInstanceId": 187507,
     "sourceId": 219868,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.688988,
   "end_time": "2025-01-05T17:01:24.162382",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-05T17:01:01.473394",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
